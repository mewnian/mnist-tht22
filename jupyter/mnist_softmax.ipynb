{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = ([] for x in range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    return bin(x)[2:].zfill(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 60000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "with open('../src/data_train.txt','r') as pixels, open('../src/label_train.txt','r') as labels:\n",
    "    for l in pixels.readlines():\n",
    "        l1 = map(int, l.split())\n",
    "        l2 = list(map(convert, l1))\n",
    "        px = list(map(int,''.join(l2)))\n",
    "        lb = int(labels.readline())\n",
    "        x_train.append(px)\n",
    "        y_train.append(lb)\n",
    "with open('../src/data_test.txt','r') as pixels, open('../src/label_test.txt','r') as labels:\n",
    "    for l in pixels.readlines():\n",
    "        l1 = map(int, l.split())\n",
    "        l2 = list(map(convert, l1))\n",
    "        px = list(map(int,''.join(l2)))\n",
    "        lb = int(labels.readline())\n",
    "        x_test.append(px)\n",
    "        y_test.append(lb)\n",
    "print(len(x_train),len(y_train),len(x_test),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count, features = x_train.shape\n",
    "test_count = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 128)               204928    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,834\n",
      "Trainable params: 213,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# first model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_shape=(1600,)))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 0.8549 - accuracy: 0.7422 - val_loss: 0.3062 - val_accuracy: 0.9107\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 2s 40ms/step - loss: 0.3318 - accuracy: 0.9028 - val_loss: 0.2188 - val_accuracy: 0.9383\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 2s 35ms/step - loss: 0.2483 - accuracy: 0.9276 - val_loss: 0.1764 - val_accuracy: 0.9497\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 2s 36ms/step - loss: 0.2003 - accuracy: 0.9411 - val_loss: 0.1532 - val_accuracy: 0.9551\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 2s 42ms/step - loss: 0.1678 - accuracy: 0.9503 - val_loss: 0.1386 - val_accuracy: 0.9584\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 2s 41ms/step - loss: 0.1471 - accuracy: 0.9570 - val_loss: 0.1243 - val_accuracy: 0.9632\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 2s 39ms/step - loss: 0.1267 - accuracy: 0.9622 - val_loss: 0.1166 - val_accuracy: 0.9643\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 2s 43ms/step - loss: 0.1136 - accuracy: 0.9656 - val_loss: 0.1077 - val_accuracy: 0.9677\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 2s 45ms/step - loss: 0.1012 - accuracy: 0.9695 - val_loss: 0.1051 - val_accuracy: 0.9688\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 2s 40ms/step - loss: 0.0879 - accuracy: 0.9734 - val_loss: 0.1022 - val_accuracy: 0.9697\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0825 - accuracy: 0.9746 - val_loss: 0.0983 - val_accuracy: 0.9698\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.0739 - accuracy: 0.9768 - val_loss: 0.0973 - val_accuracy: 0.9703\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 2s 34ms/step - loss: 0.0683 - accuracy: 0.9794 - val_loss: 0.0955 - val_accuracy: 0.9709\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0607 - accuracy: 0.9815 - val_loss: 0.0941 - val_accuracy: 0.9718\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0546 - accuracy: 0.9833 - val_loss: 0.0912 - val_accuracy: 0.9721\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0510 - accuracy: 0.9849 - val_loss: 0.0900 - val_accuracy: 0.9735\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.0476 - accuracy: 0.9844 - val_loss: 0.0924 - val_accuracy: 0.9722\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0445 - accuracy: 0.9862 - val_loss: 0.0902 - val_accuracy: 0.9739\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0397 - accuracy: 0.9879 - val_loss: 0.0905 - val_accuracy: 0.9741\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.0894 - val_accuracy: 0.9740\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0344 - accuracy: 0.9891 - val_loss: 0.0901 - val_accuracy: 0.9744\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.0915 - val_accuracy: 0.9743\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.0917 - val_accuracy: 0.9753\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 1s 32ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.0905 - val_accuracy: 0.9753\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0259 - accuracy: 0.9919 - val_loss: 0.0938 - val_accuracy: 0.9753\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.0944 - val_accuracy: 0.9744\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.0906 - val_accuracy: 0.9761\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.0953 - val_accuracy: 0.9758\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0936 - val_accuracy: 0.9765\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0922 - val_accuracy: 0.9768\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.0975 - val_accuracy: 0.9753\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0970 - val_accuracy: 0.9759\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0966 - val_accuracy: 0.9758\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.1002 - val_accuracy: 0.9759\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0991 - val_accuracy: 0.9752\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.1011 - val_accuracy: 0.9762\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0980 - val_accuracy: 0.9766\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0994 - val_accuracy: 0.9763\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.1022 - val_accuracy: 0.9755\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.1037 - val_accuracy: 0.9763\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.1077 - val_accuracy: 0.9752\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.1045 - val_accuracy: 0.9754\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1103 - val_accuracy: 0.9753\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.1064 - val_accuracy: 0.9764\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.1046 - val_accuracy: 0.9758\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.1049 - val_accuracy: 0.9760\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.1038 - val_accuracy: 0.9755\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.1056 - val_accuracy: 0.9757\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.1082 - val_accuracy: 0.9762\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.1121 - val_accuracy: 0.9752\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.1038 - val_accuracy: 0.9778\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.1079 - val_accuracy: 0.9762\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1107 - val_accuracy: 0.9774\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.1097 - val_accuracy: 0.9766\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1116 - val_accuracy: 0.9753\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.1122 - val_accuracy: 0.9757\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1115 - val_accuracy: 0.9757\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1128 - val_accuracy: 0.9744\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.1103 - val_accuracy: 0.9762\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1136 - val_accuracy: 0.9762\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.1139 - val_accuracy: 0.9760\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1132 - val_accuracy: 0.9773\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1145 - val_accuracy: 0.9769\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.1220 - val_accuracy: 0.9764\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.1171 - val_accuracy: 0.9762\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1188 - val_accuracy: 0.9762\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.1218 - val_accuracy: 0.9758\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.1216 - val_accuracy: 0.9761\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.1154 - val_accuracy: 0.9762\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.1192 - val_accuracy: 0.9764\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1272 - val_accuracy: 0.9753\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1191 - val_accuracy: 0.9768\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.1195 - val_accuracy: 0.9774\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1185 - val_accuracy: 0.9767\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1171 - val_accuracy: 0.9763\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.1244 - val_accuracy: 0.9759\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1258 - val_accuracy: 0.9768\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.1198 - val_accuracy: 0.9774\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.1229 - val_accuracy: 0.9771\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.1247 - val_accuracy: 0.9759\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.1172 - val_accuracy: 0.9774\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.1261 - val_accuracy: 0.9751\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.1283 - val_accuracy: 0.9761\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.1282 - val_accuracy: 0.9768\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1253 - val_accuracy: 0.9766\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.1230 - val_accuracy: 0.9758\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.1316 - val_accuracy: 0.9755\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1266 - val_accuracy: 0.9776\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1302 - val_accuracy: 0.9767\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1275 - val_accuracy: 0.9767\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.1274 - val_accuracy: 0.9760\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1310 - val_accuracy: 0.9759\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1260 - val_accuracy: 0.9764\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.1381 - val_accuracy: 0.9741\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1302 - val_accuracy: 0.9761\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1281 - val_accuracy: 0.9764\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1327 - val_accuracy: 0.9767\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1372 - val_accuracy: 0.9747\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.1318 - val_accuracy: 0.9765\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1296 - val_accuracy: 0.9773\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1116 - accuracy: 0.9788\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1HklEQVR4nO3deZxdVZnv/89Tp+ZKpapSmScSQiCEKYEYUZBBUEFFhpufHdRW0q1cEBuw7W6x7W6Hq/fSv0Z/Nu2A6EVRkUEEREVGI0gzJiGEJAQzkKFSGSqVpFKp6UzP74+1q+pU5SQ5CXU4SdX3/XrVq87Z01n7DM+z11p7r23ujoiISH9FhS6AiIgcmZQgREQkKyUIERHJSglCRESyUoIQEZGslCBERCQrJQgRwMx+ambfyHHZ9WZ2Yb7LJFJoShAiIpKVEoTIIGJmxYUugwweShBy1Iiadv7RzJaZWZuZ/V8zG2NmfzCzVjN70szqMpb/iJmtMLPdZvYnMzsxY95sM1sSrXcvUN7vtT5sZkujdZ8zs1NzLOOHzOwVM9tjZpvM7Kv95p8dbW93NP+qaHqFmX3LzDaYWYuZPRtNO8/MGrK8DxdGj79qZveb2S/MbA9wlZnNNbPno9fYYmbfNbPSjPVPMrMnzGynmW0zs382s7Fm1m5m9RnLnWFmTWZWksu+y+CjBCFHm/8BvA84HrgE+APwz8BIwvf5egAzOx64G7gRGAU8AvzWzEqjYPkQ8HNgBPCraLtE654O3AH8T6Ae+CHwsJmV5VC+NuCTQC3wIeBaM7ss2u7kqLz/FZVpFrA0Wu8W4Azg3VGZ/glI5/ieXArcH73mXUAK+DzhPXkXcAHw2agM1cCTwKPAeOA44Cl33wr8CfhoxnY/Adzj7okcyyGDjBKEHG3+y923uftm4M/Ai+7+irt3AQ8Cs6Pl/gr4vbs/EQW4W4AKQgA+EygBvuPuCXe/H3g54zU+A/zQ3V9095S73wl0ResdkLv/yd1fc/e0uy8jJKlzo9kfB55097uj121296VmVgT8DXCDu2+OXvO5aJ9y8by7PxS9Zoe7L3b3F9w96e7rCQmuuwwfBra6+7fcvdPdW939xWjenYSkgJnFgCsJSVSGKCUIOdpsy3jckeX5sOjxeGBD9wx3TwObgAnRvM3ed6TKDRmPjwG+EDXR7Daz3cCkaL0DMrN3mtnCqGmmBbiGcCRPtI21WVYbSWjiyjYvF5v6leF4M/udmW2Nmp3+dw5lAPgNMNPMjiXU0lrc/aXDLJMMAkoQMlg1EgI9AGZmhOC4GdgCTIimdZuc8XgT8E13r834q3T3u3N43V8CDwOT3L0GuA3ofp1NwLQs6+wAOvczrw2ozNiPGKF5KlP/IZl/AKwCprv7cEIT3MHKgLt3AvcRajp/jWoPQ54ShAxW9wEfMrMLok7WLxCaiZ4DngeSwPVmVmxmVwBzM9b9EXBNVBswM6uKOp+rc3jdamCnu3ea2VzgYxnz7gIuNLOPRq9bb2azotrNHcC3zWy8mcXM7F1Rn8dfgPLo9UuAfwEO1hdSDewB9prZDODajHm/A8aa2Y1mVmZm1Wb2zoz5PwOuAj4C/CKH/ZVBTAlCBiV3f4PQnv5fhCP0S4BL3D3u7nHgCkIg3EXor3ggY91FhH6I70bz10TL5uKzwNfNrBX4N0Ki6t7uRuCDhGS1k9BBfVo0+x+A1wh9ITuBfweK3L0l2uaPCbWfNqDPWU1Z/AMhMbUSkt29GWVoJTQfXQJsBVYD52fM/29C5/iSqP9ChjDTDYNEJJOZ/RH4pbv/uNBlkcJSghCRHmb2DuAJQh9Ka6HLI4WlJiYRAcDM7iRcI3GjkoOAahAiIrIfqkGIiEhWg2pgr5EjR/qUKVMKXQwRkaPG4sWLd7h7/2trgEGWIKZMmcKiRYsKXQwRkaOGmW3Y3zw1MYmISFZKECIikpUShIiIZKUEISIiWeUtQZjZHWa23cyW72e+mdmtZrbGwh3CTs+Yd5GZvRHNuylfZRQRkf3LZw3ip8BFB5h/MTA9+ruaMERx93DG34vmzwSuNLOZeSyniIhkkbcE4e7PEEal3J9LgZ958AJQa2bjCMMur3H3ddGom/dEy4qIyNuokNdBTKDvnbAaomnZpmeOV9+HmV1NqIEwefLk/S0mIm+jdNrpSqbpTKQoMqOqLEZx7MDHo8lUmt0dCdJpZ1R1GX3v57Qvd2dDczurtu5hXE0FJ4ytprwklnW57a1dNLV2sbcrSVtXksrSYsbXljO2ppyy4r7rtMeTbNzZTmcizfiackYOK6OoyEinnT2dCfZ2JTEzjHCnpo54ko54ms5kimTKcXdS7sSTaeLJNIm0U2RQXFREcZFRWRpjWHkxVWXFFBf13UfDMIPmtjgNu9pp2NVBWXERU0dWMW3UMEYPL6M0VoSZ0RFPsbZpL6u3t7KnI8mn3j0ll4/mkBQyQWT79P0A07Ny99uB2wHmzJmjgaUk79yd5rY4Xck0Y4eXE4t+5Lvb47ywrpmVjXtIpJ20O4YxoqqE+qoyRgwrjX7cIRB0JJK0dibZ25UEoCRWREnMGFZWQm1lCcPLS2iLJ9m+p4um1k5aOhK0xVN0xFMAVJbGqCorJpV2drcn2N0epy2eJJV2kmnHgIrSGOUlMUqKimhPpGjvStIeTxFPheCVSjvlJUVUlMaoKIlRXFRELGbEouDs0f6WxoooKymiJFbEjr1dNOzqYPOuDtrjKdIe9rX3/YFket+fYllxEVVlxZQVF1FWXERRkYUAmkrTHk/R2pnsWbausoSTJ9QwbdQw3J14Kk1XVN5k2mnrSvJaQwvNbfGedWJFxrEjqxhbU86IqlJqKkrYuLOd5Ztb2LE3vk95ulWXFYf9L43R1pVix96+twIviRlVZcXs6UiQZbcKoqy4iHgqTffbXltZwiffdcxBk+qhKmSCaCDcArLbRMJtIkv3M12kRyKVZnd7gp1tcZpau2ja28mutgTDyoqpqypleHkxTXu72LSzg8272ykvjlE/rIz6qlJGVpcyujoEkbVNe3l2zQ6eW9PM7o44ZcUxSmNFjK0p55QJNZw6sYaSWBHLGnazdFMLa7a3sqWlk65kGgjBY9KISkpjRbyxrRV3MIPiIqPIjLQ7idTARZXuI1CAtniKVBSxhpUVU1NRwrCyYopjRnGRkXboSISEkkynqSot7kkE5SVFDC8vJlZkdCbStMeT7GxLkEqHINy93aIo4HQH6HgyTf2wUibWVXLS+BqGlcUoivY1MzSVxIooj14n7dAWHbm3xZPEk2FbybRTFiuitDgsW1tZQl1lKQCvb9nD8sYWfr24gVjMKI0V9STQoiKjrDjGeSeM5oxj6jhp/HC2tHSwsnEPr29tpam1i40729nVFmd8bQXnnTCak8cPZ1xtBdVl4ci9rSvJ5t0dNO7uZHdHnI54io5EirLiIo6pr2LyiErKS2JsbemgsaWTtq4ktRUl1FSWUl0WwmbaHTMoL4lRWVpMeUkRsaKQXIuK+pbZgWTKe5Jh93uRSvdNrB5tt66ylIl1FUysq6ArmWZdUxvrmvb2HJh0JVNUlMQ4fkw1x48ZxjH1VQOeHKCwCeJh4HNmdg+hCanF3beYWRMw3cymEu6gNZ++t22Uo1AylWZXe4K2rnDEvLs9QdPezqjan+pZrj364W7e3UFzxlFfd7U9FTVdZB5tHkxNRQnxZJqORCrr/JKYcfrkOqaPHtHTLLJxZzsL39hO5mDHx46q4qTxNbz/pLGMqymnvCTGhuZ2NjS3sbcryQdPGce7ptVz2sRaSouLesq9tyvJjr1xdrbFe4Kvu1NZVkx1eTHDooCTiI7q93YlaelI0NKRoLI0xujqckYPL6O2orRnu93b7kqmKTLrM30oOm1SLRedPK7QxciLamDksDLmTh3xtr923hKEmd0NnAeMNLMG4CtACYC73wY8Qrj94hqgHVgQzUua2eeAx4AYcIe7r8hXOeWtaelIsLJxD427O9jWGgK+e2j+qCiJ0djSyYrGFlZtbSUeHXUfSHlJEeNrK5hQW8Fxo4b1HBV1H5XHioySWBF1laWMqCqhrqqUUcPKGFVdRl1lKXu7kuxqj9PSkWDksDImjajsCcAd8dB8sGNvV1Tr6GJ8TQVzp46gqmzfn0JbV5IVjXtIptKcNKGGmoqSQ35/zIzq8hKqy0uYOrLqkNc/2LaztbmLDJRBdT+IOXPmuAbrG3idiRQNu9pZv6O95+h+0852Vm7Zw4bm9j7LVpXGKDKjPRGaP4aXF3PyhBpOGj+8J1hXlRVTW1HCqOoQ2IeVFeeleiwiB2dmi919TrZ5g2o0Vzl8m3d3sGTDLl7ZuJtVW/fQFnVmtnYm2dba2aeppay4iAm1FcwcN5yPzpnEyRNqOGZEJaOHl1FZGr5SHrW9l8RMwV/kKKUEMUS1x5Ms3bSbP76+nT+u2s66HW1AaOKZMXY4dVWljK8NZ8lMqqtkyshKJo+oZGJdJSOHlR406JsZpcVKDCJHMyWIQa6lI8ErG3excWc7G5rbeXNHG3/Z1krDrg4ASmNFnDmtnk+ceQzvmDKCGeOqKTnI+eoiMjQoQQxSa7bv5afPvcmvF2/uOXunvKSIKfVVzJ5cx0fnTGLmuOG8a1p91g5aERFFhkHE3Xl+bTO3/3kdf3qjidJYER+ZNZ4rTp/AcaOG5XR1qohINyWIo1BnIsUflm/h7pc20dqZZFJdBeNrK1i0YSfLN+9h5LBSPn/h8Xz8zMmMHFZW6OKKyFFKCeIosrWlkzufX8+9L29iZ1ucY0dWMWVkFRua2/nvNTsYV1vBzVecwmWzJ+j8eBF5y5QgjgIrG/fwoz+v47evNpJ2530zx/DJd03h3dPq1WQkInmjBHEEW7O9lW8/8RceeW0rVaUxPvmuKSw4awqTRlQWumgiMgQoQRyBmvd28X/+sIoHljRQWVrMDRdM52/OnnpYQz2IiBwuJYgjiLvz+9e28JXfrGBPZ4K/PXsq1553HCOqSgtdNHmruvbC6sdg4lyondR3XsduKKuGorep3ygZh+ICf6cSHZCKQ3nNoa+bTkP7DigdBqUHqE0nOqG4LAzkNVDi7bDrTRh5PMSOkAM2d2jbAcNGDfimlSCOEJt2tvON36/ksRXbOHViDb+cdyYnjK0udLFyE28Pwa04OmMqlYTmNbD1NdjTEL687c1QMwlOmw/10w7/tbq3vWcztG4J2y2tgvJaqKiFMSdD9dje5Tv3wPaVMGJabj+gVBI2L4ZEG4yaAdXjegOMe/gr2s+FhO7QuhU6d4cA0h3w33wGfnMd7N4IGEx/H5w8D3b8JSSNra+FYDduFkw4HY67AI45G2KH+PPsbIEdq3ufF8VCAC6vDZ/Byt/Ayodg23Ioq4Hh42D4eKidHP5qJvUG3ZLKEABjpeGvamTYTvd7kU5DVwt0tYbPPxH9dT+umQjjZ/e+BzvfhFfvho3PQ/O68L0AqJkMY0+BUSdA1ajob2QoV/W48J3aujx8JlteDZ9l0xvh8wEoqQqf6+R3wfEfgCnvgQ3/DUt/CaufgPGz4OL/FyZmDDWU6IDtr4ftNK2CeBuUVIR9Hj4Oxp8Oo2f2ff+TXbD4TvjzLbB3GxRXwIQzYNypvYmiqCR8t0fNCJ9/aVV4v9zD93T3Bti7HY45C8qH9/3s4u2wpxHamkLy69gVPs/OFhh9Isy8rPe9dIeGReG7s3kxbF4SDjA+v/zQvi850GB9Bba7Pc53/7iGnz2/gaIiuOGC4/nMe6Ye9O5beZHsCl+4xqWQ7AjB0lNgsfBjKa6A0TPCD7+8Fhpehpd+FIJOKg6l1VA5IvyAkp292y2ugMr6ENRxmPzusJ3mtbBzHbTvDNuPlQIG6UR47eIyGDMTxp4a1t/4QggwXXsOvB/V42HMSeEHuWM1PfehmnA6TH9/KHv3j88sBIaSihA41zwVAny38hqoGJGxfFEIfrWTQ5kSHSEgduwMQTC+N6xXUQdTzw1BYuldMOJYeP83oPEVWPJz2Ls1vK+TzwzLtTVB45KQLFJxqBwJJ14SttO6JfwlMt7Tuikw40MhmbTvhBd+AEvu7H39/Zn0Tph6Tqi1tG4JQWn3xhCUDqa4AqrHhH1ub4b0QYZcL68Jr9W+MwRtLHx3Rh4P9ceFgLdtRdjn5jXhu7aP7vu2EZLH6JkhYI44NgT29mZo2RSScMeu3tWqx4X35/Xfhu/jaR+Dmgmw/tkQXNOJsFysNCTFREf4zmfua/1x4aCjvAa2LIOWjSG4n3ZlKPemF0OC8WiU4lRi330oKqbnO92tajRc+NWwnY6d8Nyt4XeU6DvwZR8jjoWzPx++qy98P/xOLRbejwmnh7/Zn9z/wcsBHGiwPiWIAmhpT/D06ib++Po2nnp9O23xJPPOmMjfv+8ExtaU576hZDwErMwjHfcQSBtfCUdZ8fbw5ew+EkzFw1HunsYQ8LqPnJKd4YeT+SM5kKrR0LYdyobDqX8VAkdbcwg0w8aEo8Kxp4RAVhoNc92yGZbdG44k924PP8D6aSEYppOhnJ4OR2KxUoi3hqPH7StD+eqnw5SzQ1CtnRyCQHeQ7mwJQXbrsvDj2bYyLDPhjJAsti2Hv0RHXN0Bp6QqPO7+YVaNguPeB8e/P2y36Y1wpNm1JySV8ppQzpZNIah27Op9/8prwo+4/riwv+ufhbULQxA+81p477/2NoekkuHzGXlcSACZ4u2w5glY8RD85dHweQ0bG2pF3e8jHoJqxy4oLg+BCeCUeeFIs/uINhUPNajOljDt+ItCkMwm3ha+E/G9US0gagJKJ8KBw97tUaLaGvajcmQ40i+rDvtfWtX7v7gcdrwR9n/dn0KiP21+CIg1E7O/fjodEnPbjhDQW7dCa2Mo15iTQwAcPmH/zUWpJGxeFN738bPg2PNDAupqhWdugee/F75b42eF79CEM2BUlGi6fz/pVDio2Lwk/BZ2re89MKiog/f8PUx774HLsHMdNL0e/ie7ovcwFb6rtZND096fbg4HV6NPCq+RaA+f3fToe1c1MhyUlNeE93PV70PNZcur4XVGTAvfqdPmh/f/LVKCOILcv7iBf37gNeKpNCOqSjn/hNF85pypzBg7/OArQwgGaxfCa/eFL05xGcz4MJx0efgRv/D9ECS7WSwEh+6jG4uFYFM9LhwdJbvCj9AstI9PORsmzQ1fvFhp+JGlU+GLHm8LgalxSQick98VkkPZsLy8V737nAxBunIAbpjSsTsEirLhvYHBPQTE4vLDOgLbL4+ST09gP0SpRPi8spUplYSNz8GqR0LQecenQwCS7Np3hqP5/k07hZBOhwOl//7PcPBy7hdh1PEHXsc91JLSySj5Ddz3VAniCHHXixv48oPLOeu4ev7+fScwa1Jtz/2M+3APwX7L0t4mnz2be9vy04lwRDvz0hCA3vhDb9PCqBnh6GLGJVGQL+nbbgwDGwRF5Kim+0EcAe549k2+/ruVfOCEWm69oJQy3oAN8XAE39IQmix2b+htl+9uZ7eiEPTrpoT226qR4Uj/uAt7z0RJdISqfEllaPPdXxVYiUFEDoESRL6lkjz4+4fZ9eLvebRuLSdsfh27o3Pf5YqKQxtr/bTQxDNiWjhDYuypB2/CKamAEy7OT/lFZMhSgsiXLcvg6X+na/WfuDy1l3SJYcNPxqb+TdTGPzy08ReX9Z7S93adBy8ikgMliHx44w/4/X9Dh5fxUNc7SEw5l0/M/yRFw+oLXTIRkZwpQQwkd3jxNvzRL9FYeQKX7byeC95xCv/78lMoytYZLSJyBFOCeKu6TzdcuxDWPgVbXuWVyrP52M6/5eNnz+DLHzxRyUFEjkpKEG9FOgX3fjxc0FRUTGLcGdxZ9Rlu3nku/3bpKXzyXVMKXUIRkcOmBPFWPP4vITlc+FXisxfwV3euYNWeVm7769lcOHNMoUsnIvKW6MT4w7XoJ+Gq5XdeA2d/nm882cArG3fzrY+epuQgIoOCEsThWPtHeOQfwrg97/8mD72ymZ89v4GrzzmWD54yrtClExEZEEoQh+qVu+Cuj4YRKefdwaqmdm56YBnvnDqCf/rACYUunYjIgFGCyFU6BY//K/zms3DMu2HBI6RKq/mHX71KdXkJ//Wx2YUZoltEJE/USZ0Ld3jos7DsnjBq5kU3Q6yEe17cwPLNe7j1ytmMrj6EYbpFRI4CShC5WPzTkBzO+xKcdxMAu9ri/Mdjb/DOqSO45FT1O4jI4JPXNhEzu8jM3jCzNWZ2U5b5dWb2oJktM7OXzOzkjHnrzew1M1tqZoUbw3vbSnj0pnCjkHP+qWfyLY+/QWtnkq9fejI2kPe8FRE5QuStBmFmMeB7wPuABuBlM3vY3VdmLPbPwFJ3v9zMZkTLX5Ax/3x3z+FeiHkSb4f7F4SB9S7/Yc9w2cs3t/DLlzay4N1Tj577RouIHKJ81iDmAmvcfZ27x4F7gEv7LTMTeArA3VcBU8zsyLmI4Il/DbedvOJ2GDa6Z/K/P7qK+qpSbnzf9AIWTkQkv/KZICYAmzKeN0TTMr0KXAFgZnOBY4Dum9Y68LiZLTazq/f3ImZ2tZktMrNFTU1NA1Z4OlvCzeXP+BRMO79n8uptrfx59Q4WnDWV4eUlA/d6IiJHmHwmiGwN8/3vb3ozUGdmS4G/A14BktG8s9z9dOBi4DozOyfbi7j77e4+x93njBo1amBKDuF+z6kumPWJPpN/8tx6yoqLuHKu7v8rIoNbPs9iagAmZTyfCDRmLuDue4AFABZ6et+M/nD3xuj/djN7kNBk9Uwey9vXa7+C2mNgYu+tWne3x3lgSQOXzZrAiKrSt60oIiKFkM8axMvAdDObamalwHzg4cwFzKw2mgfwaeAZd99jZlVmVh0tUwW8H1iex7L2tbcJ1j0Np8zrc3/nu1/aRGcizYKzp7xtRRERKZS81SDcPWlmnwMeA2LAHe6+wsyuiebfBpwI/MzMUsBK4G+j1ccAD0anjxYDv3T3R/NV1n2sfAg8BSfP65mUTKX5+fPrefe0emaMHf62FUVEpFDyeqGcuz8CPNJv2m0Zj58H9jkVyN3XAafls2wH9NqvYPRJMGZmz6THVmyjsaWTr1168gFWFBEZPDR4UH+7NsCmF+GU/9Fn8i9f2sCkERW8d8bo/awoIjK4KEH0t/zX4f/JvQliT2eCF9ft5EOnjCem24eKyBChBNHfigdh4lyom9Iz6dnVO0imnQtOVO1BRIYOJYhMqSRsXwlTzuoz+anXt1NTUcLsSbWFKZeISAEoQWRq2QjpJIyY1jMpnXae/st2zj1+lO73ICJDiiJepuZ14X99b4JYtrmFHXvj6pwWkSFHCSLTzrXhf0YN4o+rtlNkcO7xAziMh4jIUUAJIlPzWigd1mfk1oWrtjN7ch11GlpDRIYYJYhMO9fCiGN7htfYvqeT1za3qHlJRIYkJYhMzWv79D8sfGM7gBKEiAxJShDdUgnYvXGf/odxNeXM0F3jRGQIUoLotmtDGKAvowbx6qYWzjy2XvecFpEhSQmiW78zmFo7E2zd08n0McMKWCgRkcJRgujWHCWIqAaxtqkNgONGKUGIyNCkBNFt51ooq4HKeiDcexrguNFKECIyNClBdGteC/W9p7iuadpLaayIySMqC1wwEZHCUILotnNtnzOY1m7fy5SRlRp/SUSGLEU/gGQXtDT0OYNpzfa9al4SkSFNCQJg13rwdE8NojORYuPOdo4bresfRGToUoKAfc5gWt/cRtrVQS0iQ5sSBGRcA3EsAKu37QV0iquIDG1KEBBqEBV1UDkCCP0PZnDsqKoCF0xEpHCUIGCfM5jWNO1lUl0l5SWxAhZKRKSwlCAg3Emuvu8prup/EJGhTgkinYLqMTD2FABSaWfdjjamK0GIyBBXXOgCFFxRDD7zx56nm3a2E0+mmaYEISJDnGoQ/azZHp3BpAQhIkOcEkQ/q5UgREQAJYh9rNm+l9HVZQwvLyl0UURECiqvCcLMLjKzN8xsjZndlGV+nZk9aGbLzOwlMzs513XzZU2TzmASEYE8JggziwHfAy4GZgJXmtnMfov9M7DU3U8FPgn85yGsmxdbWzqYUFvxdryUiMgRLZ81iLnAGndf5+5x4B7g0n7LzASeAnD3VcAUMxuT47p5kUg5ZSVqeRMRyWcknABsynjeEE3L9CpwBYCZzQWOASbmuC7Releb2SIzW9TU1PSWCx1PpimN6QpqEZF8JgjLMs37Pb8ZqDOzpcDfAa8AyRzXDRPdb3f3Oe4+Z9SoUW+huEE8laakONvLi4gMLfm8UK4BmJTxfCLQmLmAu+8BFgCYmQFvRn+VB1s3H9ydRCpNqe4iJyKSWw3CzH5tZh8ys0OJnC8D081sqpmVAvOBh/tttzaaB/Bp4JkoaRx03XxIph13lCBERMi9iekHwMeA1WZ2s5nNONgK7p4EPgc8BrwO3OfuK8zsGjO7JlrsRGCFma0inLF0w4HWPYT9OiyJVBqAkmIlCBGRnJqY3P1J4EkzqwGuBJ4ws03Aj4BfuHtiP+s9AjzSb9ptGY+fB6bnum6+JZKhm6NENQgRkdw7qc2sHriK0BT0CuGahdOBJ/JSsgLoSqUAKFUNQkQktxqEmT0AzAB+Dlzi7luiWfea2aJ8Fe7tlkiFGkRpTGcxiYjkehbTd939j9lmuPucASxPQSWSoQ9CNQgRkdybmE40s9ruJ9EYSp/NT5EKJ97dSa0+CBGRnBPEZ9x9d/cTd98FfCYvJSqgeFIJQkSkW66RsCi6kA3oGUyv9ADLH5W6axBqYhIRyb0P4jHgPjO7jTDkxTXAo3krVYH09EGoBiEiknOC+CLwP4FrCeMkPQ78OF+FKpTus5jUxCQikvuFcmnC1dQ/yG9xCiuu6yBERHrkeh3EdOD/EO7fUN493d2PzVO5CiLecyW1roMQEcn1UPknhNpDEjgf+BnhorlBpXssJvVBiIjkniAq3P0pwNx9g7t/FXhv/opVGHFdKCci0iPXTurOaKjv1Wb2OWAzMDp/xSqMhC6UExHpkWskvJFwE5/rgTOATwCfylOZCiah6yBERHoctAYRXRT3UXf/R2Av0R3gBqMuXUktItLjoJHQ3VPAGZlXUg9WvaO5KkGIiOTaB/EK8Bsz+xXQ1j3R3R/IS6kKRJ3UIiK9ck0QI4Bm+p655MCgShCJVJoig1jRoK8siYgcVK5XUg/afodMiVRa/Q8iIpFcr6T+CaHG0Ie7/82Al6iAupJpNS+JiERybWL6XcbjcuByoHHgi1NYiVRaHdQiIpFcm5h+nfnczO4GnsxLiQookVINQkSk2+FGw+nA5IEsyJEgnlQfhIhIt1z7IFrp2wexlXCPiEElkXKN5CoiEsm1iak63wU5EsRTaUqLY4UuhojIESGn9hQzu9zMajKe15rZZXkrVYHEk2lKVYMQEQFy74P4iru3dD9x993AV/JSogLSdRAiIr1yjYbZlsv1FNmjRlzXQYiI9Mg1Gi4ys2+b2TQzO9bM/j9gcT4LVgiqQYiI9Mo1Gv4dEAfuBe4DOoDr8lWoQomnXAlCRCSS61lMbcBNh7pxM7sI+E8gBvzY3W/uN78G+AXhmopi4BZ3/0k0bz3QCqSApLvPOdTXP1TxZIoyNTGJiAC5n8X0hJnVZjyvM7PHDrJODPgecDEwE7jSzGb2W+w6YKW7nwacB3zLzEoz5p/v7rPejuQAug5CRCRTrofLI6MzlwBw910c/J7Uc4E17r7O3ePAPcCl/ZZxoDq6GdEwYCeQzLFMA05DbYiI9Mo1GqbNrGdoDTObQpbRXfuZAGzKeN4QTcv0XeBEwsB/rwE3uHs6mufA42a22Myu3t+LmNnVZrbIzBY1NTXltDP7o6E2RER65Xqq6peBZ83s6ej5OcB+g3YkW1tN/6TyAWAp4UZE04AnzOzP7r4HOMvdG81sdDR9lbs/s88G3W8HbgeYM2fOwZLWAcV1FpOISI+coqG7PwrMAd4gnMn0BcKZTAfSAEzKeD6RfYcIXwA84MEa4E1gRvSajdH/7cCDhCarvEqk0uqkFhGJ5NpJ/WngKUJi+ALwc+CrB1ntZWC6mU2NOp7nAw/3W2YjcEH0GmOAE4B1ZlZlZtXR9Crg/cDyXMr6VqiJSUSkV67R8AbgHcAGdz8fmA0csMHf3ZPA54DHgNeB+9x9hZldY2bXRIv9L+DdZvYaIQF90d13AGMITVqvAi8Bv49qMXmTSjtpRwlCRCSSax9Ep7t3mhlmVubuq8zshIOt5O6PAI/0m3ZbxuNGQu2g/3rrgNNyLNuASKRC37jOYhIRCXJNEA3RdRAPETqMdzHIbjnalQwJQtdBiIgEuV5JfXn08KtmthCoAfLa5PN2Uw1CRKSvQx6R1d2fPvhSR594VIMoVR+EiAhw+PekHnS6axDqpBYRCRQNI2piEhHpS9Ew0ttJrbdERASUIHokUmGUjtJincUkIgJKED16mphisQKXRETkyKAEEYnrOggRkT6UICLx7rOY1EktIgIoQfRI6DoIEZE+FA0jcZ3mKiLSh6JhRBfKiYj0pWgY6RlqQzUIERFACaJHPLoOQmcxiYgEShCR7k7qMl0HISICKEH06D3NVTUIERFQguiR0FhMIiJ9KBpGEqk0ZlBcpBqEiAgoQfToSqUpiRVhpgQhIgJKED0SSddV1CIiGRQRI4lUWtdAiIhkUESMxJNpXQMhIpJBCSKSiPogREQkUESMdKmJSUSkD0XESCKZVie1iEgGRcSIOqlFRPpSRIzE1QchItKHImIkkXSdxSQikiGvCcLMLjKzN8xsjZndlGV+jZn91sxeNbMVZrYg13UHWjyVprRYI7mKiHTLW4IwsxjwPeBiYCZwpZnN7LfYdcBKdz8NOA/4lpmV5rjugIon05SqBiEi0iOfNYi5wBp3X+fuceAe4NJ+yzhQbWEApGHATiCZ47oDStdBiIj0lc+IOAHYlPG8IZqW6bvAiUAj8Bpwg7unc1wXADO72swWmdmipqamwy6szmISEekrnxExW3uN93v+AWApMB6YBXzXzIbnuG6Y6H67u89x9zmjRo067MKGoTaUIEREuuUzIjYAkzKeTyTUFDItAB7wYA3wJjAjx3UHVDzlShAiIhnyGRFfBqab2VQzKwXmAw/3W2YjcAGAmY0BTgDW5bjugIonU5SpiUlEpEdxvjbs7kkz+xzwGBAD7nD3FWZ2TTT/NuB/AT81s9cIzUpfdPcdANnWzVdZARIpXQchIpIpbwkCwN0fAR7pN+22jMeNwPtzXTef1EktItKXIiKQTjvJtPogREQyKSISrqIGlCBERDIoIhKalwB1UouIZFBEJFwDAapBiIhkUkQknMEEShAiIpkUEeltYtJZTCIivRQRga6eJiZdByEi0k0JgowahJqYRER6KCLS20mtJiYRkV6KiPTWINRJLSLSSxGR3gvlVIMQEemV17GYjha6DkLkyJNIJGhoaKCzs7PQRRkUysvLmThxIiUlJTmvowRB73UQ6qQWOXI0NDRQXV3NlClTCHcllsPl7jQ3N9PQ0MDUqVNzXk8REV0HIXIk6uzspL6+XslhAJgZ9fX1h1wbU0Qks4lJX0SRI4mSw8A5nPdSCQKN5ioiko0iIhrNVUT2tXv3br7//e8f8nof/OAH2b179wGX+bd/+zeefPLJwyzZ20cREZ3FJCL72l+CSKVSB1zvkUceoba29oDLfP3rX+fCCy98K8V7W+gsJjIulFMNQuSI9LXfrmBl454B3ebM8cP5yiUn7Xf+TTfdxNq1a5k1axYlJSUMGzaMcePGsXTpUlauXMlll13Gpk2b6Ozs5IYbbuDqq68GYMqUKSxatIi9e/dy8cUXc/bZZ/Pcc88xYcIEfvOb31BRUcFVV13Fhz/8YebNm8eUKVP41Kc+xW9/+1sSiQS/+tWvmDFjBk1NTXzsYx+jubmZd7zjHTz66KMsXryYkSNHDuj7cCCKiOg0VxHZ180338y0adNYunQp//Ef/8FLL73EN7/5TVauXAnAHXfcweLFi1m0aBG33norzc3N+2xj9erVXHfddaxYsYLa2lp+/etfZ32tkSNHsmTJEq699lpuueUWAL72ta/x3ve+lyVLlnD55ZezcePG/O3sfqgGgUZzFTnSHehI/+0yd+7cPtcQ3HrrrTz44IMAbNq0idWrV1NfX99nnalTpzJr1iwAzjjjDNavX59121dccUXPMg888AAAzz77bM/2L7roIurq6gZyd3KiBEFoYiqNFemUOhHZr6qqqp7Hf/rTn3jyySd5/vnnqays5Lzzzst6jUFZWVnP41gsRkdHR9Ztdy8Xi8VIJpNAuLit0NSmQuikVu1BRDJVV1fT2tqadV5LSwt1dXVUVlayatUqXnjhhQF//bPPPpv77rsPgMcff5xdu3YN+GscjGoQhBqEOqhFJFN9fT1nnXUWJ598MhUVFYwZM6Zn3kUXXcRtt93GqaeeygknnMCZZ5454K//la98hSuvvJJ7772Xc889l3HjxlFdXT3gr3MgdiRUYwbKnDlzfNGiRYe83pceWMZTr2/npS8f+aediQwVr7/+OieeeGKhi1EwXV1dxGIxiouLef7557n22mtZunTpW9pmtvfUzBa7+5xsy6sGQeik1jUQInIk2bhxIx/96EdJp9OUlpbyox/96G0vgxIE4TRXDdQnIkeS6dOn88orrxS0DIqKQCKZ1jUQIiL9KCoSBusrKdZZTCIimZQg6L0OQkREeuU1KprZRWb2hpmtMbObssz/RzNbGv0tN7OUmY2I5q03s9eieYd+atIhiKuTWkRkH3mLimYWA74HXAzMBK40s5mZy7j7f7j7LHefBXwJeNrdd2Yscn40P+spWAMlnkqrk1pE3pJhw4YB0NjYyLx587Iuc95553GwU/G/853v0N7e3vM8l+HD8yWfUXEusMbd17l7HLgHuPQAy18J3J3H8uyXmphEZKCMHz+e+++//7DX758gchk+PF/yeZrrBGBTxvMG4J3ZFjSzSuAi4HMZkx143Mwc+KG7376fda8GrgaYPHnyYRVUTUwiR7g/3ARbXxvYbY49BS6+eb+zv/jFL3LMMcfw2c9+FoCvfvWrmBnPPPMMu3btIpFI8I1vfINLL+173Lt+/Xo+/OEPs3z5cjo6OliwYAErV67kxBNP7DMW07XXXsvLL79MR0cH8+bN42tf+xq33norjY2NnH/++YwcOZKFCxf2DB8+cuRIvv3tb3PHHXcA8OlPf5obb7yR9evX73dY8bcqn1Ex22lB+7ts+xLgv/s1L53l7qcTmqiuM7Nzsq3o7re7+xx3nzNq1KjDKmgi5RpqQ0T6mD9/Pvfee2/P8/vuu48FCxbw4IMPsmTJEhYuXMgXvvCFAw6q94Mf/IDKykqWLVvGl7/8ZRYvXtwz75vf/CaLFi1i2bJlPP300yxbtozrr7+e8ePHs3DhQhYuXNhnW4sXL+YnP/kJL774Ii+88AI/+tGPeq6TyHVY8UOVzxpEAzAp4/lEoHE/y86nX/OSuzdG/7eb2YOEJqtn8lBO4roOQuTIdoAj/XyZPXs227dvp7GxkaamJurq6hg3bhyf//zneeaZZygqKmLz5s1s27aNsWPHZt3GM888w/XXXw/Aqaeeyqmnntoz77777uP2228nmUyyZcsWVq5c2Wd+f88++yyXX355z6iyV1xxBX/+85/5yEc+kvOw4ocqnwniZWC6mU0FNhOSwMf6L2RmNcC5wCcyplUBRe7eGj1+P/D1fBU0dFLrOggR6WvevHncf//9bN26lfnz53PXXXfR1NTE4sWLKSkpYcqUKVmH+c6U7TYCb775Jrfccgsvv/wydXV1XHXVVQfdzoFqKrkOK36o8nbY7O5JQp/CY8DrwH3uvsLMrjGzazIWvRx43N3bMqaNAZ41s1eBl4Dfu/uj+SprIqU+CBHZ1/z587nnnnu4//77mTdvHi0tLYwePZqSkhIWLlzIhg0bDrj+Oeecw1133QXA8uXLWbZsGQB79uyhqqqKmpoatm3bxh/+8IeedfY3zPg555zDQw89RHt7O21tbTz44IO85z3vGcC93Vdex2Jy90eAR/pNu63f858CP+03bR1wWj7LlklDbYhINieddBKtra1MmDCBcePG8fGPf5xLLrmEOXPmMGvWLGbMmHHA9a+99loWLFjAqaeeyqxZs5g7dy4Ap512GrNnz+akk07i2GOP5ayzzupZ5+qrr+biiy9m3LhxffohTj/9dK666qqebXz6059m9uzZA9aclI2G+wZuvOcVzj1hFJfPnpiHUonI4Rjqw33ng4b7PgzfmT+70EUQETniqF1FRESyUoIQkSPWYGoCL7TDeS+VIETkiFReXk5zc7OSxABwd5qbmykvLz+k9dQHISJHpIkTJ9LQ0EBTU1OhizIolJeXM3HioZ2IowQhIkekkpISpk6dWuhiDGlqYhIRkayUIEREJCslCBERyWpQXUltZk3AgQdH2b+RwI4BLM7RYCjuMwzN/R6K+wxDc78PdZ+Pcfes90oYVAnirTCzRfm+temRZijuMwzN/R6K+wxDc78Hcp/VxCQiIlkpQYiISFZKEL2y3vN6kBuK+wxDc7+H4j7D0NzvAdtn9UGIiEhWqkGIiEhWShAiIpLVkE8QZnaRmb1hZmvM7KZClydfzGySmS00s9fNbIWZ3RBNH2FmT5jZ6uh/XaHLOtDMLGZmr5jZ76LnQ2Gfa83sfjNbFX3m7xrs+21mn4++28vN7G4zKx+M+2xmd5jZdjNbnjFtv/tpZl+K4tsbZvaBQ3mtIZ0gzCwGfA+4GJgJXGlmMwtbqrxJAl9w9xOBM4Hron29CXjK3acDT0XPB5sbgNczng+Fff5P4FF3n0G4v/vrDOL9NrMJwPXAHHc/GYgB8xmc+/xT4KJ+07LuZ/Qbnw+cFK3z/Sju5WRIJwhgLrDG3de5exy4B7i0wGXKC3ff4u5LosethIAxgbC/d0aL3QlcVpAC5omZTQQ+BPw4Y/Jg3+fhwDnA/wVw97i772aQ7zdhdOoKMysGKoFGBuE+u/szwM5+k/e3n5cC97h7l7u/CawhxL2cDPUEMQHYlPG8IZo2qJnZFGA28CIwxt23QEgiwOgCFi0fvgP8E5DOmDbY9/lYoAn4SdS09mMzq2IQ77e7bwZuATYCW4AWd3+cQbzP/exvP99SjBvqCcKyTBvU5/2a2TDg18CN7r6n0OXJJzP7MLDd3RcXuixvs2LgdOAH7j4baGNwNK3sV9TmfikwFRgPVJnZJwpbqiPCW4pxQz1BNACTMp5PJFRLByUzKyEkh7vc/YFo8jYzGxfNHwdsL1T58uAs4CNmtp7QfPheM/sFg3ufIXyvG9z9xej5/YSEMZj3+0LgTXdvcvcE8ADwbgb3Pmfa336+pRg31BPEy8B0M5tqZqWEzpyHC1ymvDAzI7RJv+7u386Y9TDwqejxp4DfvN1lyxd3/5K7T3T3KYTP9o/u/gkG8T4DuPtWYJOZnRBNugBYyeDe743AmWZWGX3XLyD0sw3mfc60v/18GJhvZmVmNhWYDryU81bdfUj/AR8E/gKsBb5c6PLkcT/PJlQtlwFLo78PAvWEsx5WR/9HFLqsedr/84DfRY8H/T4Ds4BF0ef9EFA32Pcb+BqwClgO/BwoG4z7DNxN6GdJEGoIf3ug/QS+HMW3N4CLD+W1NNSGiIhkNdSbmEREZD+UIEREJCslCBERyUoJQkREslKCEBGRrJQgRI4AZnZe92izIkcKJQgREclKCULkEJjZJ8zsJTNbamY/jO41sdfMvmVmS8zsKTMbFS07y8xeMLNlZvZg9xj9ZnacmT1pZq9G60yLNj8s4x4Od0VXBIsUjBKESI7M7ETgr4Cz3H0WkAI+DlQBS9z9dOBp4CvRKj8DvujupwKvZUy/C/ieu59GGC9oSzR9NnAj4d4kxxLGkhIpmOJCF0DkKHIBcAbwcnRwX0EYFC0N3Bst8wvgATOrAWrd/elo+p3Ar8ysGpjg7g8CuHsnQLS9l9y9IXq+FJgCPJv3vRLZDyUIkdwZcKe7f6nPRLN/7bfcgcavOVCzUVfG4xT6fUqBqYlJJHdPAfPMbDT03Af4GMLvaF60zMeAZ929BdhlZu+Jpv818LSHe3A0mNll0TbKzKzy7dwJkVzpCEUkR+6+0sz+BXjczIoIo2leR7ghz0lmthhoIfRTQBh2+bYoAawDFkTT/xr4oZl9PdrG//M27oZIzjSaq8hbZGZ73X1YocshMtDUxCQiIlmpBiEiIlmpBiEiIlkpQYiISFZKECIikpUShIiIZKUEISIiWf3/ZvaFkzC2BMYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.112\n",
      "Test accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=1024, epochs=100, shuffle=True, validation_split=.2)\n",
    "loss, accuracy  = model.evaluate(x_test, y_test, batch_size=1024)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(f'Test loss: {loss:.3}')\n",
    "print(f'Test accuracy: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600, 160), (1, 160), (160, 80), (1, 80))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wList = model.get_weights()\n",
    "wList[1] = np.reshape(wList[1], (1, wList[1].shape[0]))\n",
    "wList[3] = np.reshape(wList[3], (1, wList[3].shape[0]))\n",
    "wList[0].shape, wList[1].shape, wList[2].shape, wList[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52633288, 0.79781019, 0.44142488],\n",
       "       [0.34382392, 0.72944401, 0.67294535],\n",
       "       [0.60343267, 0.90389384, 0.63711104],\n",
       "       [0.91448962, 0.62933447, 0.98152573]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(4,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.88284977],\n",
       "       [0.68764785, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * (a < 0.5) / 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('text.txt','w') as g:\n",
    "#     g.write('{')\n",
    "#     for i in range(len(wList)):\n",
    "#         g.write('{')\n",
    "#         for j in range(wList[i].shape[0]):\n",
    "#             g.write('{')\n",
    "#             for k in range(wList[i][j].shape[0]):\n",
    "#                 g.write(str(wList[i][j][k]))\n",
    "#                 if k + 1 == wList[i][j].shape[0]: g.write('}')\n",
    "#                 else: g.write(',')\n",
    "#             if j + 1 == wList[i].shape[0]: g.write('}')\n",
    "#             else: g.write(',')\n",
    "#         if i + 1 == len(wList): g.write('}')\n",
    "#         else: g.write(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wList = model.get_weights()\n",
    "wList[1] = np.reshape(wList[1], (1, wList[1].shape[0]))\n",
    "wList[3] = np.reshape(wList[3], (1, wList[3].shape[0]))\n",
    "wList[5] = np.reshape(wList[5], (1, wList[5].shape[0]))\n",
    "\n",
    "MXX = 100000\n",
    "name = ['w1', 'b1', 'w2', 'b2','w3','b3']\n",
    "with open('text.txt','w') as g:\n",
    "    for i in range(len(wList)):\n",
    "        g.write('ld v' + name[i] + '[' + str(wList[i].shape[0]) + '][' + str(wList[i].shape[1]) + '] =' + '{')\n",
    "        for j in range(min(MXX,wList[i].shape[0])):\n",
    "            g.write('{')\n",
    "            for k in range(min(MXX,wList[i][j].shape[0])):\n",
    "                g.write(str(wList[i][j][k]))\n",
    "                if k + 1 == min(MXX,wList[i][j].shape[0]): g.write('}')\n",
    "                else: g.write(',')\n",
    "            if j + 1 == min(MXX,wList[i].shape[0]): g.write('}')\n",
    "            else: g.write(',')\n",
    "        g.write(';\\n')\n",
    "    g.write('\\nMatrix ')\n",
    "    for i in range(len(wList)):\n",
    "        g.write(name[i] + '(' + str(wList[i].shape[0]) + ',' + str(wList[i].shape[1]) + ')')\n",
    "        if i + 1 == len(wList): g.write(';')\n",
    "        else: g.write(', ')\n",
    "    g.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wList = model.get_weights()\n",
    "wList[1] = np.reshape(wList[1], (1, wList[1].shape[0]))\n",
    "wList[3] = np.reshape(wList[3], (1, wList[3].shape[0]))\n",
    "wList[5] = np.reshape(wList[5], (1, wList[5].shape[0]))\n",
    "\n",
    "MXX = 100000\n",
    "name = ['w1', 'b1', 'w2', 'b2','w3','b3']\n",
    "with open('params.txt','w') as g:\n",
    "    for i in range(len(wList)):\n",
    "        for j in range(min(MXX,wList[i].shape[0])):\n",
    "            for k in range(min(MXX,wList[i][j].shape[0])):\n",
    "                g.write(str(wList[i][j][k]))\n",
    "                if k + 1 == min(MXX,wList[i][j].shape[0]): g.write('\\n')\n",
    "                else: g.write(' ')\n",
    "            if j + 1 == min(MXX,wList[i].shape[0]): g.write('\\n')\n",
    "            else: g.write(' ')\n",
    "        g.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.51754904 -0.45539743 -0.4437031  ...  0.3656878   0.38041222\n",
      "  0.38910335]\n",
      "[-0.14273882 -0.13065885 -0.11109908 -0.101748   -0.10004844 -0.09944563\n",
      " -0.09559857 -0.09087021 -0.08486159 -0.08222348 -0.08166708 -0.07909302\n",
      " -0.07136677 -0.07135327 -0.06750135 -0.06634451 -0.06591669 -0.06574912\n",
      " -0.06131806 -0.05938933 -0.05778539 -0.05735597 -0.0569664  -0.05661343\n",
      " -0.05584927 -0.05379893 -0.05344805 -0.05194208 -0.05173174 -0.05039058\n",
      " -0.05023504 -0.0498016  -0.04976648 -0.04847743 -0.04746494 -0.04549221\n",
      " -0.04505241 -0.04363222 -0.04353971 -0.04290259 -0.03362965 -0.03333264\n",
      " -0.03327519 -0.03295882 -0.0317222  -0.02998892 -0.02814448 -0.02715767\n",
      " -0.0257194  -0.02342554 -0.02317237 -0.02301632 -0.02190301 -0.02183115\n",
      " -0.02090498 -0.0203338  -0.01989912 -0.01897573 -0.01718469 -0.01635731\n",
      " -0.013437   -0.01315749 -0.01305237 -0.01300407 -0.01297964 -0.01245059\n",
      " -0.01183554 -0.01084054 -0.01051321 -0.01035974 -0.00975334 -0.00968551\n",
      " -0.00956826 -0.00934782 -0.00861201 -0.00825034 -0.00790763 -0.00734618\n",
      " -0.00637173 -0.00522644 -0.00495364 -0.00474478 -0.00432488 -0.00371526\n",
      " -0.0025274   0.00017459  0.00135967  0.00143222  0.0025385   0.00327878\n",
      "  0.00352512  0.00583478  0.0076758   0.00880428  0.01032369  0.01053401\n",
      "  0.01057392  0.01060041  0.01128764  0.01206249  0.01306079  0.01346833\n",
      "  0.01438688  0.01478796  0.01972249  0.02026141  0.02047646  0.02062478\n",
      "  0.02260677  0.02456327  0.02534247  0.02564617  0.02808428  0.02995254\n",
      "  0.03043068  0.0314012   0.03379297  0.03451163  0.03505186  0.03518614\n",
      "  0.03602462  0.03643883  0.03834098  0.04020744  0.04245152  0.04321612\n",
      "  0.04413801  0.04470893  0.04485279  0.0448691   0.04520037  0.04523263\n",
      "  0.04544967  0.04713532  0.04811009  0.0486918   0.0487708   0.05740689\n",
      "  0.05857089  0.06042402  0.06163343  0.06344788  0.06395935  0.06600213\n",
      "  0.06639411  0.06976272  0.0729184   0.07909482  0.08383264  0.10039346\n",
      "  0.10263091  0.10601959  0.10712489  0.10823659  0.10898218  0.10928389\n",
      "  0.11126613  0.11232628  0.14067407  0.14772718]\n",
      "[-0.6005375  -0.5321441  -0.5302364  ...  0.57171494  0.57403135\n",
      "  0.6566696 ]\n",
      "[-0.07571894 -0.07461737 -0.07233751 -0.04647769 -0.04404022 -0.03596128\n",
      " -0.0359527  -0.0265836  -0.02627832 -0.02613668 -0.02360992 -0.0231388\n",
      " -0.0216901  -0.0208458  -0.01858786 -0.0150798  -0.0122138  -0.01067419\n",
      " -0.00970009 -0.00753198 -0.00730038 -0.00505322 -0.00377671 -0.00197794\n",
      "  0.00521445  0.00544054  0.00776635  0.00858686  0.00905873  0.01023913\n",
      "  0.01024908  0.01169081  0.01428614  0.01568724  0.01599699  0.01837418\n",
      "  0.01855648  0.02089446  0.02287897  0.02408992  0.02426003  0.024704\n",
      "  0.02489714  0.0256875   0.02584042  0.02796767  0.02799544  0.03343822\n",
      "  0.03502751  0.03783982  0.04178929  0.04727435  0.04816948  0.0485143\n",
      "  0.04887812  0.05119835  0.05623315  0.05652608  0.05711037  0.05776228\n",
      "  0.05943416  0.06147255  0.06153903  0.06274037  0.07399622  0.07415383\n",
      "  0.07474577  0.07663612  0.07671078  0.08076671  0.08197739  0.08466915\n",
      "  0.08738837  0.08867759  0.08988866  0.09353306  0.09402229  0.11769843\n",
      "  0.13097717  0.13763475]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(np.unique(wList[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n"
     ]
    }
   ],
   "source": [
    "s=\"\"\"0000000000000000000000000000000000000000\n",
    "0000000000000000000000000000000000000000\n",
    "0000000000000000000000000000000000000000\n",
    "0000000000000000000000000000000000000000\n",
    "0000000000000000000000000011100000000000\n",
    "0000000000000000000000001111110000000000\n",
    "0000000000000000000000011111110000000000\n",
    "0000000000000000000000111111110000000000\n",
    "0000000000000000000001111111110000000000\n",
    "0000000000000000000011111111100000000000\n",
    "0000000000000000000111111100000000000000\n",
    "0000000000000000011111111000000000000000\n",
    "0000000000000000011111100000000000000000\n",
    "0000000000000000111111000000000000000000\n",
    "0000000000000001111110000000000000000000\n",
    "0000000000000001111100000000000000000000\n",
    "0000000000000011111000000000000000000000\n",
    "0000000000000011111000000000000000000000\n",
    "0000000000000111111000000000000000000000\n",
    "0000000000000111111111111110000000000000\n",
    "0000000000000111111111111111000000000000\n",
    "0000000000000111111111111111000000000000\n",
    "0000000000000111111111111111100000000000\n",
    "0000000000000111111111111111100000000000\n",
    "0000000000000111111110001111100000000000\n",
    "0000000000000111111100001111100000000000\n",
    "0000000000000111110000001111100000000000\n",
    "0000000000000111110000111111100000000000\n",
    "0000000000000111111111111111000000000000\n",
    "0000000000000111111111111110000000000000\n",
    "0000000000000111111111111100000000000000\n",
    "0000000000000001111111110000000000000000\n",
    "0000000000000000111111000000000000000000\n",
    "0000000000000000000000000000000000000000\n",
    "0000000000000000000000000000000000000000\n",
    "0000000000000000000000000000000000000000\n",
    "0000000000000000000000000000000000000000\n",
    "0000000000000000000000000000000000000000\n",
    "0000000000000000000000000000000000000000\n",
    "0000000000000000000000000000000000000000\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "s=''.join(s.split('\\n'))\n",
    "t = ''\n",
    "for x in s: t += (str(int(x) % 2) + ' ')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 194ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred = np.array([float(x) for x in s])\n",
    "x_pred = np.reshape(x_pred,(1,-1))\n",
    "# x_pred.shape\n",
    "np.argmax(model.predict(x_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.1466525    3.76654357  -3.34531887 -20.14275285  -1.08978856\n",
      "    1.03216707  21.25963193  -4.70694876 -10.37880048 -11.81635796]]\n"
     ]
    }
   ],
   "source": [
    "t = np.dot(x_pred,wList[0]) + wList[1]\n",
    "t = np.maximum(0, t)\n",
    "\n",
    "t = np.dot(t,wList[2]) + wList[3]\n",
    "t = np.maximum(0, t)\n",
    "\n",
    "t = np.dot(t,wList[4]) + wList[5]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\x80' in position 0: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-6f5b60fa5e61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'str.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\x80' in position 0: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# with open('str.txt','w') as f:\n",
    "#     for x in range(256): f.write(chr(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
